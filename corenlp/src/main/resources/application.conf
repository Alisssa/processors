corenlp {

  language = English

  tokenize.language = en

  #pos.model = edu/stanford/nlp/models/pos-tagger/spanish/spanish-distsim.tagger
  #ner.model = edu/stanford/nlp/models/ner/spanish.ancora.distsim.s512.crf.ser.gz

  parser {
    # NOTE: the GENIA training data should be combined with the WSJ training data
    trainFile = /net/kate/storage/data/nlp/corpora/GENIA/stanford-basic-dependencies/train.conllx
    # NOTE: the GENIA dev data should be combined with the WSJ dev data
    devFile = /net/kate/storage/data/nlp/corpora/GENIA/stanford-basic-dependencies/dev.conllx
    embeddings = /net/kate/storage/data/nlp/corpora/causal-assembly/pmc-openaccess-dim-300.model # CoreNLP doesn't expect the dimensions on the first line for some reason...
    # the length (number of features) of the embeddings
    embeddingsDim = "200"
    # the trained model will be saved to this file
    model = en-bio-dep-parser.model.txt.gz
  }

}
